# –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∞–Ω–µ–∫–¥–æ—Ç–æ–≤

from config import morph
import random
import re

from aiohttp import ClientSession
from bs4 import BeautifulSoup



async def get_anek():
    '''–ü–∞—Ä—Å–∏—Ç —Å–ª—É—á–∞–π–Ω—ã–π –∞–Ω–µ–∫–¥–æ—Ç —Å —Å–∞–π—Ç–∞ anecdotica.ru'''
    
    # –ê–Ω–µ–∫–¥–æ—Ç–∏–∫–∞ –ø—Ä—è–º –Ω–∞ –≥–ª–∞–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –∞–Ω–µ–∫–¥–æ—Ç, 
    # –ø–æ—ç—Ç–æ–º—É –º—ã –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –≤—ã—Ç–∞—Å–∫–∏–µ–º –¥–∏–≤ —Å —Ç–µ–∫—Å—Ç–æ–º
    async with ClientSession(trust_env=True) as session:
        async with session.get("http://anecdotica.ru/", ssl=False) as response:
            html = await response.text()
            soup = BeautifulSoup(html, "lxml")
            result = soup.find_all("div", class_="item_text")[0]
            
    return result.text
        
        
async def get_anek_pro(anek_result):
    '''–ò—â–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –∞–Ω–µ–∫–¥–æ—Ç –ø–æ —Ç–µ–∫—Å—Ç—É —é–∑–µ—Ä–∞ —Å —Å–∞–π—Ç–∞ anecdotica.ru'''
    
    async with ClientSession(trust_env=True) as session:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–∞–±–æ—Ä —Å–∫–ª–æ–Ω–µ–Ω–∏–π –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        try:
            words = [
                morph.parse(anek_result)[0].normal_form,
                morph.parse(anek_result)[0].inflect({'gent'}).word,
                morph.parse(anek_result)[0].inflect({'datv'}).word,
                morph.parse(anek_result)[0].inflect({'accs'}).word,
                morph.parse(anek_result)[0].inflect({'ablt'}).word,
                morph.parse(anek_result)[0].inflect({'loct'}).word
            ]
        except AttributeError:
            words = [anek_result]
            
        for word in words:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º —Å—Ä–∞–∑—É –∫ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–∏—Å–∫–∞, –≤—Å—Ç–∞–≤–ª—è—è –≤ –Ω–µ—ë –Ω–∞—à –∑–∞–ø—Ä–æ—Å
            url = f'http://anecdotica.ru/search?mode=0&index={word}&series=0&format=0&category=0&country=0&lang=0&action=search'
            async with session.get(url, ssl=False) as response:
                html = await response.text()
                soup = BeautifulSoup(html, "lxml")
                
                # –ù–∞—Ö–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–∏—Å–∫–∞
                result_pgmenu = soup.find_all("div", class_="pgmenu")
                
                # –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–∏—Å–∫–∞ –Ω–µ—Ç - —Ç–æ —Å–∞–π—Ç –≤–æ–æ–±—â–µ –∞–Ω–µ–∫–¥–æ—Ç–æ–≤ –Ω–µ –Ω–∞—à–µ–ª
                # –ï—Å–ª–∏ –µ—Å—Ç—å - –∑–Ω–∞—á–∏—Ç –µ—Å—Ç—å —á—Ç–æ –ø–∞—Ä—Å–∏—Ç—å
                if result_pgmenu:
                    # –°–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    result_pgmenu_result = result_pgmenu[0]
                    result_page_number = result_pgmenu_result.text.split(' ')[2].split('/')[1]
                    
                    # –ï—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–∏—Å–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ:
                    if int(result_page_number) > 1:
                        # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Ç–∞–º –Ω–µ–º–Ω–æ–≥–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è id
                        a_elements = result_pgmenu_result.find_all('a', href=True)
                        search_page_url = a_elements[1]['href']
                        
                        # –°–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∞–Ω–µ–∫–¥–æ—Ç–∞–º–∏
                        random_number = random.randint(1, int(result_page_number))
                        
                        # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –Ω—É–∂–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
                        pattern = re.compile(r'page=(\d+)')
                        pattern_result = pattern.sub(f'page={random_number}', search_page_url)
                        new_url = 'http://anecdotica.ru/' + pattern_result

                        # –ò —É–∂–µ –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ —à—É—Ç–∫–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é
                        async with session.get(new_url, ssl=False) as response:
                            html = await response.text()
                            soup = BeautifulSoup(html, "lxml")
                            result_items = soup.find_all("div", class_="item_text")
                            choise_joke = random.choice(result_items)
                            
                            return choise_joke.text
                            
                    # –ï—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –æ–¥–Ω–∞, —Ç–æ –º–æ–∂–µ–º –ø—Ä—è–º –Ω–∞ –Ω–µ–π –Ω–∞–π—Ç–∏ –≤—Å–µ –∞–Ω–µ–∫–¥–æ—Ç—ã –∏ –≤—ã–±—Ä–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π
                    else:
                        result_items = soup.find_all("div", class_="item_text")
                        choise_joke = random.choice(result_items)
                        
                        return choise_joke.text

        # # –ï—Å–ª–∏ –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏—é —Ü–∏–∫–ª–∞ –Ω–µ –Ω–∞—à–ª–∏ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∞–Ω–µ–∫–¥–æ—Ç–∞, —Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —é–∑–µ—Ä—É –ø–µ—á–∞–ª—å–∫—É
        # answers = ['–Ø, –ö–û–ù–ï–ß–ù–û, –¢–£–ü–û–ô –†–û–ë–û–¢, –ù–û –¢–ê–ö–û–ô –•–£–ô–ù–ò –î–ê–ñ–ï –Ø –ù–ê–ô–¢–ò –ù–ï –ú–û–ì–£', '–ù–£ –ù–ï –ó–ù–ê–Æ –Ø –¢–ê–ö–ò–• –ê–ù–ï–ö–î–û–¢–û–í, –ù–ï –ó–ù–ê –Æ', 'ü§®']
        # choise_answer = random.choice(answers)
        choise_answer = None
        
        return choise_answer